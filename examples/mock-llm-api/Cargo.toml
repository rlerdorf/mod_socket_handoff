[package]
name = "mock-llm-api"
version = "0.1.0"
edition = "2021"
rust-version = "1.80"
description = "High-performance mock OpenAI-compatible streaming API server for benchmarking"
license = "Apache-2.0"

[dependencies]
tokio = { version = "1", features = ["full"] }
axum = "0.7"
hyper = { version = "1", features = ["server", "http1", "http2"] }
hyper-util = { version = "0.1", features = ["tokio", "server", "server-auto", "http1", "http2"] }
tower = { version = "0.4", features = ["util"] }
clap = { version = "4", features = ["derive"] }
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["env-filter"] }
bytes = "1"
futures = "0.3"

[profile.release]
lto = true
codegen-units = 1
strip = true
